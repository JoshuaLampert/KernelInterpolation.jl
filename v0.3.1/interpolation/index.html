<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Interpolation · KernelInterpolation.jl</title><meta name="title" content="Interpolation · KernelInterpolation.jl"/><meta property="og:title" content="Interpolation · KernelInterpolation.jl"/><meta property="twitter:title" content="Interpolation · KernelInterpolation.jl"/><meta name="description" content="Documentation for KernelInterpolation.jl."/><meta property="og:description" content="Documentation for KernelInterpolation.jl."/><meta property="twitter:description" content="Documentation for KernelInterpolation.jl."/><meta property="og:url" content="https://JoshuaLampert.github.io/KernelInterpolation.jl/stable/interpolation/"/><meta property="twitter:url" content="https://JoshuaLampert.github.io/KernelInterpolation.jl/stable/interpolation/"/><link rel="canonical" href="https://JoshuaLampert.github.io/KernelInterpolation.jl/stable/interpolation/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KernelInterpolation.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><span class="tocitem">Guide</span><ul><li><a class="tocitem" href="../nodesets/">Sets of nodes</a></li><li class="is-active"><a class="tocitem" href>Interpolation</a><ul class="internal"><li><a class="tocitem" href="#Mathematical-background"><span>Mathematical background</span></a></li><li><a class="tocitem" href="#Performing-an-interpolation"><span>Performing an interpolation</span></a></li><li><a class="tocitem" href="#Visualizing-the-results"><span>Visualizing the results</span></a></li><li><a class="tocitem" href="#Overview-of-kernels-and-adding-a-custom-kernel"><span>Overview of kernels and adding a custom kernel</span></a></li><li><a class="tocitem" href="#Next-steps"><span>Next steps</span></a></li><li><a class="tocitem" href="#References"><span>References</span></a></li></ul></li><li><a class="tocitem" href="../pdes/">Solving PDEs by collocation</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../tutorial_differentiating_interpolation/">1D interpolation and differentiation</a></li><li><a class="tocitem" href="../tutorial_noisy_data/">Dealing with noisy data</a></li></ul></li><li><a class="tocitem" href="../development/">Development</a></li><li><a class="tocitem" href="../ref/">Reference</a></li><li><a class="tocitem" href="../changelog/">Changelog</a></li><li><a class="tocitem" href="../license/">License</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Guide</a></li><li class="is-active"><a href>Interpolation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Interpolation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JoshuaLampert/KernelInterpolation.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JoshuaLampert/KernelInterpolation.jl/blob/main/docs/src/interpolation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="classical_interpolation"><a class="docs-heading-anchor" href="#classical_interpolation">Classical interpolation</a><a id="classical_interpolation-1"></a><a class="docs-heading-anchor-permalink" href="#classical_interpolation" title="Permalink"></a></h1><p>Kernel methods are well-suited to interpolate given function values, which are known at scattered data points in any space dimension. In this tutorial, we will discuss the basics of kernel-based interpolation methods and how these can be implemented using KernelInterpolation.jl.</p><h2 id="Mathematical-background"><a class="docs-heading-anchor" href="#Mathematical-background">Mathematical background</a><a id="Mathematical-background-1"></a><a class="docs-heading-anchor-permalink" href="#Mathematical-background" title="Permalink"></a></h2><p>The general aim of scattered data interpolation is to find a function <span>$s:\Omega\to\mathbb{R}$</span>, a so-called <em>interpolant</em>, approximating an unknown function <span>$f:\Omega\to\mathbb{R}$</span> mapping a (potentially high-dimensional) domain <span>$\Omega\subset\mathbb{R}^d$</span> to the real numbers. We assume, we only know values <span>$f_i$</span> of the function <span>$f$</span> at some specific points <span>$x_i\in\Omega, i = 1, \ldots, N$</span>. These values could, e.g., be the measurements of an experiment. The interpolation task is to determine a (continuous) interpolant <span>$s$</span> that exactly takes the values</p><p class="math-container">\[\begin{equation}\label{eq:interpolationconditions}
    s(x_i) = f_i\quad \forall i\in\{1,\ldots, N\},
\end{equation}\]</p><p>but is defined for any <span>$x\in\Omega$</span>. A common way to solve such problems is to restrict the space of possible interpolants to search in to be finite-dimensional (we take it <span>$N$</span>-dimensional to obtain a system with <span>$N$</span> conditions for <span>$N$</span> unknowns), i.e. we can find a finite set of basis function <span>$\{b_1, \ldots, b_N\}$</span>, such that we can express any function from the subspace of continuous functions as a linear combination of these basis functions</p><p class="math-container">\[\begin{equation}\label{eq:linearcombination}
    s(x) = \sum\limits_{j = 1}^Nc_jb_j(x),
\end{equation}\]</p><p>where <span>$c_i, i = 1,\ldots, N$</span> are the coefficients that determine <span>$s$</span>. To find an (the?) interpolant satisfying the above <span>$N$</span> conditions given by \eqref{eq:interpolationconditions}, the coefficients <span>$c = (c_i)_{i = 1,\ldots,N}\in\mathbb{R}^N$</span> need to fulfill the following system of linear equations:</p><p class="math-container">\[A_Xc = f_X,\]</p><p>where <span>$f_X = (f_i)_{i = 1,\ldots,N}\in\mathbb{R}^N$</span> is the vector of function values and the components of the <em>Vandermonde</em> matrix <span>$A_X$</span> are given by <span>$(A_X)_{ij} = b_j(x_i)$</span>. If the matrix <span>$A_X$</span> is regular, this gives a unique solution <span>$c$</span> and we found the unique interpolant <span>$s$</span> given by \eqref{eq:linearcombination}.</p><p>One important question that remains is how to choose the basis functions <span>$b_j$</span>. A criterion for a good basis is the guarantee of producing a regular Vandermonde matrix for any set of nodes <span>$X = \{x_1,\ldots, x_N\}$</span>. However, the well-known <strong>Mairhuber-Curtis</strong> theorem, e.g. Theorem 2.3 in <sup class="footnote-reference"><a id="citeref-Wendland2004" href="#footnote-Wendland2004">[Wendland2004]</a></sup>, states that there does not exist an <span>$N$</span>-dimensional subspace of the set of continuous functions such that the Vandermonde matrix is invertible <strong>for any set</strong> <span>$X = \{x_1,\ldots, x_N\}\subset\Omega$</span> if <span>$\Omega\subset\mathbb{R}^d$</span> contains an interior node and <span>$d\ge 2$</span>, <span>$N\ge 2$</span>. This negative result suggests that the basis should be chosen <strong>data-dependent</strong>, i.e. the basis functions depend on the nodes <span>$x_i$</span>. One possibility to do so is to choose <span>$b_j = K(\cdot, x_j)$</span> for a <em>kernel function</em> <span>$K: \Omega\times\Omega\to\mathbb{R}$</span>. The Vandermonde matrix corresponding to a kernel is then given by the entries <span>$(A_X)_{ij} = K(x_i, x_j)$</span>. One criterion for this matrix being invertible is that it is symmetric and positive definite. Symmetry of <span>$A_X$</span> can be achieved by demanding <span>$K$</span> to be symmetric in its both entries, i.e. <span>$K(x_i, x_j) = K(x_j, x_i)$</span>. A kernel is called <em>positive definite</em> if the corresponding matrix is positive definite. One very famous and fundamental kernel is the Gauß kernel, which is given by</p><p class="math-container">\[K(x, y) = \mathrm{e}^{-\|x - y\|_2^2}.\]</p><p>It can be shown that the Gauß kernel is positive definite. The Gauß kernel is a member of the most common class of kernel functions, namely <em>radial basis functions</em>. A <em>translation-invariant</em> kernel function is given by <span>$K(x, y) = \Phi(x - y)$</span>, where <span>$\Phi:\Omega\to\mathbb{R}^d$</span> depends only on one variable. A <em>radial basis function</em> kernel is a translation-invariant kernel, where <span>$\Phi$</span> is given by <span>$\Phi(x) = \phi(\|x\|_2)$</span> for a univariate function <span>$\phi:\mathbb{R}_{\ge 0}\to\mathbb{R}$</span>, which is sometimes called <em>basic function</em> <sup class="footnote-reference"><a id="citeref-Fasshauer2007" href="#footnote-Fasshauer2007">[Fasshauer2007]</a></sup>. The Gauß kernel, e.g., is given by the basic function</p><p class="math-container">\[\phi(r) = \mathrm{e}^{-r^2}.\]</p><p>Many radial symmetric kernels come with a parameter, the so-called <em>shape parameter</em> <span>$\varepsilon$</span>, which can be used to control the &quot;flatness&quot; of the kernel. The shape parameter simply acts as a multiplicative factor to the norm, i.e. for a general radial-symmetric kernel we take <span>$K(x, y) = \phi(\varepsilon\|x - y\|_2)$</span>.</p><p>The completion of the linear space of functions that is spanned by the basis given a specific kernel and a domain <span>$\Omega$</span>, <span>$\mathcal{H}_{K, \Omega} = \overline{\text{span}\{K(\cdot, x), x\in\Omega\}}$</span>, is called <em>native space</em> and is a (reproducing kernel) Hilbert space (RKHS), which comes with an inner product given by</p><p class="math-container">\[\langle f, g\rangle_K = \sum\limits_{i = 1}^N\sum\limits_{j = 1}^Mc_i^fc_j^gK(x_i, \xi_j),\]</p><p>for <span>$f, g\in\mathcal{H}_{K, \Omega}$</span> having the representations</p><p class="math-container">\[f(x) = \sum\limits_{i = 1}^Nc_i^fK(x, x_i) \quad\text{and}\quad g(x) = \sum\limits_{j = 1}^Mc_j^gK(x, \xi_j).\]</p><p>The corresponding norm inherited by the kernel scalar product is denoted as <span>$\|\cdot\|_K = \sqrt{\langle\cdot,\cdot\rangle_K}$</span>.</p><p>Often, it can be useful to augment the linear combination of kernel basis functions with a linear combination of multivariate polynomials <span>$p_k$</span>, i.e. the interpolant takes the form</p><p class="math-container">\[s(x) = \sum\limits_{j = 1}^Nc_jK(x, x_j) + \sum\limits_{k = 1}^Qd_kp_k(x),\]</p><p>where <span>$p_k$</span> are a basis functions (usually monomials) of the <span>$Q = \begin{pmatrix}m - 1 + d\\d\end{pmatrix}$</span>-dimensional space of polynomials of degree <span>$m - 1$</span>. To obtain a complete system of equations, we need to enforce the constraints</p><p class="math-container">\[\sum\limits_{j = 1}^Nc_jp_k(x_j) = 0, \quad\forall k = 1,\ldots,Q.\]</p><p>The linear system now consists of a system-matrix that has 4 blocks:</p><p class="math-container">\[\begin{pmatrix}A_X &amp; P\\P^T &amp; 0\end{pmatrix}\begin{pmatrix}c\\d\end{pmatrix} = \begin{pmatrix}f_X\\0\end{pmatrix},\]</p><p>where the entries of <span>$P\in\mathbb{R}^{N\times Q}$</span> are given by <span>$P_{jk} = p_k(x_j)$</span>. This strategy does not only guarantee to be able to reproduce polynomials exactly, but also leads to a larger class of possible kernels that can be taken for the interpolation because now it is not required anymore that the kernel is positive definite, but it suffices that the new system matrix <span>$\begin{pmatrix}A_X &amp; P\\P^T &amp; 0\end{pmatrix}$</span> is regular. This leads to the notion of <em>conditionally positive definite kernels of order <span>$m$</span></em>, which are kernel functions that produce an invertible system matrix provided that the interpolant is augmented by polynomials of order <span>$m$</span> (i.e. degree <span>$m - 1$</span>). It turns out that any positive definite kernel (i.e. conditionally positive definite of order 0) is also conditionally positive definite of any order <span>$m\ge 0$</span>. One popular class of conditionally positive definite kernels are the <em>polyharmonic splines</em>, which are built by the basic function</p><p class="math-container">\[\phi_k(r) = \begin{cases}
  r^k, &amp;\text{ if } k \text{ odd}\\
  r^k\log{r}, &amp;\text{ if } k \text{ even}
\end{cases}\]</p><p>and are of order <span>$m = \left\lceil{\frac{k}{2}}\right\rceil$</span> for odd <span>$k$</span> and <span>$m = \frac{k}{2} + 1$</span> for even <span>$k$</span>.</p><h2 id="Performing-an-interpolation"><a class="docs-heading-anchor" href="#Performing-an-interpolation">Performing an interpolation</a><a id="Performing-an-interpolation-1"></a><a class="docs-heading-anchor-permalink" href="#Performing-an-interpolation" title="Permalink"></a></h2><p>To perform an interpolation with KernelInterpolation.jl, we need three basic building blocks: the scattered nodes <span>$X = \{x_1,\ldots, x_N\}$</span> (see also the <a href="../nodesets/#nodesets">previous tutorial</a>), the function values at these nodes <span>$f_X$</span>, and a kernel.</p><p>We start by creating a set of 200 Halton points in a square bounded by <span>$(0.0, 0.0)$</span> and <span>$(1.0, 1.0)$</span>:</p><pre><code class="language-julia hljs">using KernelInterpolation
using QuasiMonteCarlo: sample, HaltonSample
nodes = NodeSet(sample(200, [0.0, 0.0], [1.0, 1.0], HaltonSample())&#39;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">NodeSet{2, Float64} with separation distance q = 0.011839618836487691 and 200 nodes:
  [0.0025, 0.0025]
  [0.5025, 0.3358333333333333]
  [0.2525, 0.6691666666666666]
  [0.7525, 0.11361111111111111]
  [0.1275, 0.4469444444444444]
  [0.6275, 0.7802777777777777]
  [0.3775, 0.2247222222222222]
  [0.8775, 0.5580555555555554]
  [0.065, 0.8913888888888888]
  [0.565, 0.03953703703703704]
  [0.315, 0.37287037037037035]
  [0.815, 0.7062037037037037]
  [0.19, 0.15064814814814814]
  [0.69, 0.48398148148148146]
  [0.44, 0.8173148148148146]
  [0.94, 0.26175925925925925]
  [0.03375, 0.5950925925925925]
  [0.53375, 0.9284259259259258]
  [0.28375, 0.07657407407407407]
  [0.78375, 0.40990740740740733]
  ⋮
</code></pre><p>For testing purposes, we sample the function values from a given function <span>$f$</span> (in reality, you normally do not know <span>$f$</span> of course). We pick the Franke function, which is a widely used test function.</p><pre><code class="language-julia hljs">function f(x)
    0.75 * exp(-0.25 * ((9 * x[1] - 2)^2 + (9 * x[2] - 2)^2)) +
    0.75 * exp(-(9 * x[1] + 1)^2 / 49 - (9 * x[2] + 1) / 10) +
    0.5 * exp(-0.25 * ((9 * x[1] - 7)^2 + (9 * x[2] - 3)^2)) -
    0.2 * exp(-(9 * x[1] - 4)^2 - (9 * x[2] - 7)^2)
end

f_X = f.(nodes)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">200-element Vector{Float64}:
 0.7689554233046703
 0.494634387962025
 0.30783772907342233
 0.3662320368090395
 0.6381030515624646
 0.12880192026651338
 0.849161499301568
 0.2286684433357302
 0.28908845989880366
 0.37775713090839314
 ⋮
 0.06425351679462936
 0.8529485458402957
 0.3578877362590751
 0.2485573251034497
 0.5810756532344912
 0.41332254157513876
 0.11599241435523606
 0.6806468206285681
 0.45252391948963855</code></pre><p>We can visualize the Franke function evaluated at the nodes by</p><pre><code class="language-julia hljs">using Plots
plot(nodes, f_X, zcolor = f_X)</code></pre><p><img src="../franke_function.png" alt="Franke function"/></p><p>Finally, we pick a <code>kernel</code> function and create an <a href="../ref/#Interpolation"><code>Interpolation</code></a> object by calling <a href="../ref/#KernelInterpolation.interpolate-Union{Tuple{RealT}, Tuple{Dim}, Tuple{KernelInterpolation.AbstractBasis, Vector{RealT}}, Tuple{KernelInterpolation.AbstractBasis, Vector{RealT}, NodeSet{Dim, RealT}}} where {Dim, RealT}"><code>interpolate</code></a>. Here, we choose a <a href="../ref/#KernelInterpolation.PolyharmonicSplineKernel"><code>PolyharmonicSplineKernel</code></a> of second order, i.e. <span>$k = 2$</span> (also known as <a href="../ref/#KernelInterpolation.ThinPlateSplineKernel"><code>ThinPlateSplineKernel</code></a>). The order of the polynomials will automatically be determined by the chosen kernel, but can also explicitly be passed as a fourth argument.</p><pre><code class="language-julia hljs">kernel = ThinPlateSplineKernel{dim(nodes)}()
itp = interpolate(nodes, f_X, kernel)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Interpolation with 200 nodes, kernel ThinPlateSplineKernel{2}() and polynomial of order 2.</code></pre><p>The returned object can be treated as a function and we can evaluate it at any <code>d</code>-dimensional point in space. To check that <code>itp</code> really interpolates the given data, we can call</p><pre><code class="language-julia hljs">maximum(abs.(itp.(nodes) - f_X))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.8041124150158794e-15</code></pre><p>Evaluating the interpolant in a node that is not part of the training set can be done by</p><pre><code class="language-julia hljs">x = [0.5, 0.5]
abs.(itp(x) - f(x))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.00029053321748673255</code></pre><p>Crucial for the stability of solving the linear system is the condition number of the system matrix. We can check it by</p><pre><code class="language-julia hljs">using LinearAlgebra: cond
cond(system_matrix(itp))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">42324.759978462855</code></pre><p>The condition number should be as small as possible. If it is too large, the interpolation might be unstable. The condition number depends on the choice of the kernel and the nodes. If the condition number is too large, you might want to try a different kernel or a different set. Here, we have an order of magnitude of <span>$10^5$</span>, which is acceptable.</p><h2 id="Visualizing-the-results"><a class="docs-heading-anchor" href="#Visualizing-the-results">Visualizing the results</a><a id="Visualizing-the-results-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-results" title="Permalink"></a></h2><p>To visualize the interpolation, we can use evaluate the interpolant on a grid of points and plot the result. We can use the function <a href="../ref/#KernelInterpolation.homogeneous_hypercube"><code>homogeneous_hypercube</code></a> to create a grid of points in the unit square.</p><pre><code class="language-julia hljs">N = 50
nodes_grid = homogeneous_hypercube(N, (0.0, 0.0), (1.0, 1.0))
x = unique(values_along_dim(nodes_grid, 1))
y = unique(values_along_dim(nodes_grid, 2))
z_itp = reshape(itp.(nodes_grid), (N, N))&#39;
p1 = plot(x, y, z_itp, st = :heatmap, colorbar = :none, title = &quot;Interpolation&quot;)
z_true = reshape(f.(nodes_grid), (N, N))&#39;
p2 = plot(x, y, z_true, st = :heatmap, colorbar = :none, title = &quot;True function&quot;)
plot(p1, p2, layout = (1, 2))</code></pre><p><img src="../interpolation_franke.png" alt="Interpolation of the Franke function"/></p><p>Instead of creating a grid of points with <a href="../ref/#KernelInterpolation.homogeneous_hypercube"><code>homogeneous_hypercube</code></a> and manually reshaping the result, we can also directly plot the interpolant with <code>plot(itp; x_min = 0.0, x_max = 1.0)</code>, which will automatically create a grid of points and plot the result.</p><p>For a publication-ready visualization, we can use ParaView to visualize the interpolant. We can save the values of the interpolant and the original function at the grid to a VTK file by</p><pre><code class="language-julia hljs">vtk_save(&quot;interpolation_franke&quot;, nodes_grid, itp, f, keys = [&quot;interpolant&quot;, &quot;true&quot;])</code></pre><p>In ParaView, e.g., you can now switch between the properties &quot;interpolant&quot; and &quot;true&quot; to plot the values of the interpolant and the Franke function, respectively. For looking at the scattered data, it might be helpful to change the representation to &quot;Point Gaussian&quot;. Common filters in ParaView to visualize the interpolant are the <code>Delaunay2D</code> filter to create a surface plot or <code>Warp by Scalar</code> filter to create a 3D plot.</p><h2 id="Overview-of-kernels-and-adding-a-custom-kernel"><a class="docs-heading-anchor" href="#Overview-of-kernels-and-adding-a-custom-kernel">Overview of kernels and adding a custom kernel</a><a id="Overview-of-kernels-and-adding-a-custom-kernel-1"></a><a class="docs-heading-anchor-permalink" href="#Overview-of-kernels-and-adding-a-custom-kernel" title="Permalink"></a></h2><p>In the previous example, we used the <a href="../ref/#KernelInterpolation.ThinPlateSplineKernel"><code>ThinPlateSplineKernel</code></a>, which is a predefined kernel in KernelInterpolation.jl. There is a number of different <a href="../ref/#api-kernels">kernels already defined</a>, which can be used in an analogous way. For an overview of the existing radial-symmetric kernels, see the following table.</p><table><tr><th style="text-align: right">Kernel name</th><th style="text-align: right">Formula</th><th style="text-align: right">Order</th><th style="text-align: right">Smoothness</th></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.GaussKernel"><code>GaussKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = \mathrm{e}^{-r^2}$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^\infty$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.MultiquadricKernel"><code>MultiquadricKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = (1 + r^2)^\beta, \beta &gt; 0$</span></td><td style="text-align: right"><span>$\lceil{\beta}\rceil$</span></td><td style="text-align: right"><span>$C^\infty$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.InverseMultiquadricKernel"><code>InverseMultiquadricKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = (1 + r^2)^{-\beta}, \beta &gt; 0$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^\infty$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.PolyharmonicSplineKernel"><code>PolyharmonicSplineKernel</code></a></td><td style="text-align: right"><span>$\phi_k(r) = \begin{cases} r^k, &amp;\text{ if } k \text{ odd}\\ r^k\log{r}, &amp;\text{ if } k \text{ even} \end{cases}, k\in\mathbb{N}$</span></td><td style="text-align: right"><span>$\left\lceil{\frac{k}{2}}\right\rceil$</span> for odd <span>$k$</span> and <span>$\frac{k}{2} + 1$</span> for even <span>$k$</span></td><td style="text-align: right"><span>$C^{k - 1}$</span> for odd <span>$k$</span> and <span>$C^k$</span> for even <span>$k$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.ThinPlateSplineKernel"><code>ThinPlateSplineKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = r^2\log{r}$</span></td><td style="text-align: right">2</td><td style="text-align: right"><span>$C^2$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.WendlandKernel"><code>WendlandKernel</code></a></td><td style="text-align: right"><span>$\phi_{d,k}(r) = \begin{cases}p_{d,k}(r), &amp;\text{ if } 0\le r\le 1\\0, &amp;\text{ else}\end{cases}, d, k\in\mathbb{N}$</span> for some polynomial <span>$p_{d,k}$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^{2k}$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.WuKernel"><code>WuKernel</code></a></td><td style="text-align: right"><span>$\phi_{l,k}(r) = \begin{cases}p_{l,k}(r), &amp;\text{ if } 0\le r\le 1\\0, &amp;\text{ else}\end{cases}, l, k\in\mathbb{N}$</span> for some polynomial <span>$p_{l,k}$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^{2(l - k)}$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.RadialCharacteristicKernel"><code>RadialCharacteristicKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = (1 - r)^\beta_+, \beta\ge(d + 1)/2$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^0$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.MaternKernel"><code>MaternKernel</code></a></td><td style="text-align: right"><span>$\phi_{\nu}(r) = \frac{2^{1 - \nu}}{\Gamma(\nu)}\left(\sqrt{2\nu}r\right)^\nu K_{\nu}\left(\sqrt{2\nu}r\right), \nu &gt; 0$</span></td><td style="text-align: right"><span>$0$</span></td><td style="text-align: right"><span>$C^{2(\lceil\nu\rceil - 1)}$</span></td></tr><tr><td style="text-align: right"><a href="../ref/#KernelInterpolation.RieszKernel"><code>RieszKernel</code></a></td><td style="text-align: right"><span>$\phi(r) = -r^\beta, 0 &lt; \beta &lt; 2$</span></td><td style="text-align: right"><span>$1$</span></td><td style="text-align: right"><span>$C^\infty$</span></td></tr></table><p>Kernels can be composed by using <a href="../ref/#KernelInterpolation.SumKernel"><code>SumKernel</code></a> and <a href="../ref/#KernelInterpolation.ProductKernel"><code>ProductKernel</code></a>. Anisotropic kernels can be created by using <a href="../ref/#KernelInterpolation.TransformationKernel"><code>TransformationKernel</code></a>, which applies a transformation to the input before evaluating the kernel.</p><p>However, you can also define your own kernel. A radial-symmetric kernel is a subtype of <a href="../ref/#KernelInterpolation.RadialSymmetricKernel"><code>KernelInterpolation.RadialSymmetricKernel</code></a>, which in turn is a subtype of <a href="../ref/#KernelInterpolation.AbstractKernel"><code>KernelInterpolation.AbstractKernel</code></a> and needs to implement the functions <a href="../ref/#KernelInterpolation.phi"><code>phi</code></a> and <a href="../ref/#KernelInterpolation.order"><code>order</code></a>. Let&#39;s define an exponential kernel with <span>$\phi(r) = \mathrm{e}^{-r^{1.5}}$</span> and use it for the interpolation problem above.</p><pre><code class="language-julia hljs">struct MyKernel{Dim} &lt;: KernelInterpolation.RadialSymmetricKernel{Dim} end
KernelInterpolation.phi(::MyKernel, r) = exp(-r^1.5)
KernelInterpolation.order(::MyKernel) = 0

kernel = MyKernel{2}()
itp_quadratic = interpolate(nodes, f_X, kernel)
p3 = plot(itp_quadratic; x_min = 0.0, x_max = 1.0, title = &quot;Interpolation with custom kernel&quot;, colorbar = :none)
plot(p3, p2, layout = (1, 2))</code></pre><p><img src="../interpolation_franke_custom.png" alt="Interpolation with the custom kernel"/></p><p>Kernels can be visualized by either plotting the kernel itself or together with a <a href="../ref/#KernelInterpolation.NodeSet"><code>NodeSet</code></a> to plot the multivariate form of it, or by plotting the kernel with a one-dimensional vector to plot the basic function:</p><pre><code class="language-julia hljs">x = -2.0:0.01:2.0
p_kernel = plot(x, kernel; label = &quot;Custom kernel&quot;)
plot!(p_kernel, x, GaussKernel{2}(); label = &quot;Gauss kernel&quot;, title = &quot;Basic function&quot;)
p_nodes = plot(kernel; title = &quot;Bivariate custom kernel&quot;)
plot(p_kernel, p_nodes, layout = (1, 2))</code></pre><p><img src="../kernel_custom.png" alt="Custom kernel"/></p><h2 id="Next-steps"><a class="docs-heading-anchor" href="#Next-steps">Next steps</a><a id="Next-steps-1"></a><a class="docs-heading-anchor-permalink" href="#Next-steps" title="Permalink"></a></h2><p>More examples regarding interpolation can be found in the <a href="https://github.com/JoshuaLampert/KernelInterpolation.jl/tree/main/examples/interpolation">examples</a> folder of the repository. Some easy possible tasks for further investigation are to try different kernels, more complicated sets of nodes, or different functions. When you try out to use more complex node sets, you might want to use the <code>merge</code> function to combine different <a href="../ref/#KernelInterpolation.NodeSet"><code>NodeSet</code></a>s. Note, however, that the interpolation problem might become ill-posed if the nodes are too close to each other. If there are at least twice the same nodes, the system matrix will become singular. In this case, you might want to filter out the duplicate nodes, e.g., by using <code>unique!</code>. For more information on kernel-based interpolation methods, we recommend the following references:</p><h2 id="References"><a class="docs-heading-anchor" href="#References">References</a><a id="References-1"></a><a class="docs-heading-anchor-permalink" href="#References" title="Permalink"></a></h2><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-Wendland2004"><a class="tag is-link" href="#citeref-Wendland2004">Wendland2004</a>Wendland (2004): Scattered Data Approximation, Cambridge University Press, <a href="https://doi.org/10.1017/CBO9780511617539">DOI: 10.1017/CBO9780511617539</a>.</li><li class="footnote" id="footnote-Fasshauer2007"><a class="tag is-link" href="#citeref-Fasshauer2007">Fasshauer2007</a>Fasshauer (2007): Meshfree Approximation Methods with Matlab, World Scientific, <a href="https://doi.org/10.1142/6437">DOI: 10.1142/6437</a>.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../nodesets/">« Sets of nodes</a><a class="docs-footer-nextpage" href="../pdes/">Solving PDEs by collocation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.11.3 on <span class="colophon-date" title="Thursday 15 May 2025 20:39">Thursday 15 May 2025</span>. Using Julia version 1.10.9.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
